{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import PyPDF2 \n",
    "#import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"JavaBasics-notes.txt\").read()\n",
    "text = text.replace('//', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing file and saving keywords\n",
    "new_words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = ['!','#','$','%',',','&','(',')','*','+','-','/',':',';','<','=','>','.','?','@','[',']','^','_','`','{','|','}','~','\\'',\"’\",'“','”','—','``',\"''\",'u\"',\"\\'s\",'The','•','\\'','©']\n",
    "stop_words = stopwords.words('english')\n",
    "keywords = [word for word in new_words if not word in stop_words ]\n",
    "keywords = [word for word in keywords if not word in punctuations ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Java           124\n",
       "new             52\n",
       "Basics          47\n",
       "int             40\n",
       "Button          39\n",
       "code            38\n",
       "Data            31\n",
       "class           29\n",
       "b               28\n",
       "object          26\n",
       "All             25\n",
       "method          25\n",
       "jGuru.com       23\n",
       "1996-2003       23\n",
       "Rights          23\n",
       "Reserved        23\n",
       "C++             23\n",
       "applet          22\n",
       "array           22\n",
       "public          22\n",
       "1               22\n",
       "objects         21\n",
       "*/              19\n",
       "example         19\n",
       "3               18\n",
       "5               17\n",
       "C/C++           16\n",
       "/*              16\n",
       "use             15\n",
       "0               15\n",
       "              ... \n",
       "part             1\n",
       "Topics           1\n",
       "commenting       1\n",
       "-12              1\n",
       "completely       1\n",
       "avoid            1\n",
       "well             1\n",
       "environment      1\n",
       "-23              1\n",
       "Sends            1\n",
       "complete         1\n",
       "C++-style        1\n",
       "stored           1\n",
       "precedence       1\n",
       "stat3            1\n",
       "command          1\n",
       "toString         1\n",
       "native           1\n",
       "hspace           1\n",
       "allocation       1\n",
       "Collection       1\n",
       "freeing          1\n",
       "group            1\n",
       "quitting         1\n",
       "keywords         1\n",
       "purely           1\n",
       "'\\t              1\n",
       "appropriate      1\n",
       "defense          1\n",
       "T.               1\n",
       "Length: 953, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting number of ocurrences of each keywords\n",
    "my_count = pd.Series(keywords).value_counts()\n",
    "my_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_count = pd.DataFrame({'keywords':my_count.index, 'count':my_count.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_count.to_csv('keywords.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
